{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ef73d5",
   "metadata": {},
   "source": [
    "### Author: Sebastian Brubaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336f8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import shutil\n",
    "import logging\n",
    "import search_utilities as su\n",
    "import normalization_utilities as nu\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from rapidfuzz import fuzz\n",
    "from logger import setup_logger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ef16a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538630, 5)\n",
      "(85841, 5)\n",
      "(280811, 5)\n",
      "(49342, 5)\n",
      "(243477, 5)\n",
      "(34711, 5)\n",
      "(5732, 5)\n",
      "(398, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBRUBAKE\\AppData\\Local\\Temp\\ipykernel_4420\\1216720807.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dir_tree_df = pd.read_csv(r\"experimental/eao_prj_drive_crawl_spatial.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Define globals\n",
    "\n",
    "LOGGER = setup_logger(\"logger\", log_file='logs/11-08-2025.log')\n",
    "\n",
    "IMG_MODEL = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "TXT_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "dir_tree_df = pd.read_csv(r\"experimental/eao_prj_drive_crawl_spatial.csv\")\n",
    "dir_tree_folders_df = dir_tree_df[dir_tree_df[\"is_folder\"] == True]\n",
    "\n",
    "dir_tree_2002_df = dir_tree_df[dir_tree_df[\"act_year\"] == 2002]\n",
    "dir_tree_2002_folders_df = dir_tree_2002_df[dir_tree_2002_df[\"is_folder\"] == True]\n",
    "\n",
    "dir_tree_2018_df = dir_tree_df[dir_tree_df[\"act_year\"] == 2018]\n",
    "dir_tree_2018_folders_df = dir_tree_2018_df[dir_tree_2018_df[\"is_folder\"] == True]\n",
    "\n",
    "dir_tree_spatial_df = dir_tree_df[dir_tree_df[\"act_year\"] == 'spatial']\n",
    "dir_tree_spatial_folders_df = dir_tree_spatial_df[dir_tree_spatial_df[\"is_folder\"] == True]\n",
    "\n",
    "print(dir_tree_df.shape)\n",
    "print(dir_tree_folders_df.shape)\n",
    "print(dir_tree_2002_df.shape)\n",
    "print(dir_tree_2002_folders_df.shape)\n",
    "print(dir_tree_2018_df.shape)\n",
    "print(dir_tree_2018_folders_df.shape)\n",
    "print(dir_tree_spatial_df.shape)\n",
    "print(dir_tree_spatial_folders_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7462a65",
   "metadata": {},
   "source": [
    "# BATCH LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2517d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack it all into one function for batch processing\n",
    "\n",
    "def prep_project(project_name:str, uid:int, drive_locations:list[str], top_k_images:int=10,\n",
    "                 dest_dir:str=r\"path/to/dest_dir\",\n",
    "                 search_images=True\n",
    "                 ) -> None:\n",
    "    \"\"\"\n",
    "    Do it all!\n",
    "    \"\"\"\n",
    "    dump_dir_tree = su.make_dump_dir(\"data\", root_name=project_name)\n",
    "\n",
    "    descendants = []\n",
    "    for loc in drive_locations:\n",
    "        descendants.extend(su.get_descendants(dir_tree=dir_tree_df, root=loc))\n",
    "\n",
    "    if not descendants:\n",
    "        LOGGER.critical(f\"No files found for {project_name} in any provided drive location.\")\n",
    "        return\n",
    "\n",
    "    descendants_df = pd.DataFrame(descendants)\n",
    "    descendants_path_list = list(descendants_df[\"full_path\"])\n",
    "\n",
    "    LOGGER.info(f\"Gathering files for {project_name}...\")\n",
    "    su.gather_files(descendants_path_list, dump_dir_tree[\"all_files\"], file_ext=su.ALL_TARGET_EXTENSIONS)\n",
    "    su.gather_files(descendants_path_list, dump_dir_tree[\"zip_files\"], file_ext={\".zip\"})\n",
    "\n",
    "    zip_list = os.listdir(dump_dir_tree[\"zip_files\"])\n",
    "    if (zip_list):\n",
    "        LOGGER.info(f\"Searching {project_name} zips...\")\n",
    "        zip_hits_df = su.search_type_zips(dump_dir_tree[\"zip_files\"], su.ALL_TARGET_EXTENSIONS)\n",
    "\n",
    "        zip_hits_path = os.path.join(dump_dir_tree[\"root\"], \"zip_hits.csv\")\n",
    "        zip_hits_df.to_csv(zip_hits_path)\n",
    "\n",
    "        if not zip_hits_df.empty:\n",
    "            zip_paths_list = list(zip_hits_df[\"zip_path\"])\n",
    "            members_list = list(zip_hits_df[\"member\"])\n",
    "            LOGGER.info(f\"Extracting files from {project_name} zips...\")\n",
    "            su.extract_members_from_zip(zip_paths_list, members_list, out_dir=dump_dir_tree[\"all_files\"])\n",
    "\n",
    "    local_files = os.listdir(dump_dir_tree[\"all_files\"])\n",
    "    local_file_paths = [os.path.join(dump_dir_tree[\"all_files\"], f) for f in local_files]\n",
    "\n",
    "    su.gather_files(local_file_paths, dump_dir_tree[\"shapefiles\"], file_ext=su.SHAPEFILE_EXTENSIONS)\n",
    "    su.gather_files(local_file_paths, dump_dir_tree[\"kml_files\"], file_ext={\".kml\"})\n",
    "    su.gather_files(local_file_paths, dump_dir_tree[\"kmz_files\"], file_ext={\".kmz\"})\n",
    "    su.gather_files(local_file_paths, dump_dir_tree[\"tabular_files\"], file_ext=su.TABULAR_EXTENSIONS)\n",
    "    su.gather_files(local_file_paths, dump_dir_tree[\"images\"], file_ext=su.IMAGE_EXTENSIONS)\n",
    "    su.gather_files(local_file_paths, dump_dir_tree[\"pdfs\"], file_ext={\".pdf\"})\n",
    "\n",
    "    LOGGER.info(f\"{project_name} data copied\")\n",
    "\n",
    "    LOGGER.info(f\"Converting {project_name} KMZs/KMLs to Shapefiles\")\n",
    "    nu.kmzs_to_kmls(dump_dir_tree[\"kmz_files\"], dump_dir_tree[\"kml_files\"])\n",
    "    nu.kmls_to_shapefiles(dump_dir_tree[\"kml_files\"], dump_dir_tree[\"shapefiles\"])\n",
    "    \n",
    "    LOGGER.info(f\"Tagging {project_name} Shapefiles\")\n",
    "    nu.append_id_to_shapefiles(dump_dir_tree[\"shapefiles\"], dump_dir_tree[\"prepped_shapefiles\"],\n",
    "                                            \"EPC_PP_SYD\", uid=uid)\n",
    "    \n",
    "    LOGGER.info(f\"Reprojecting {project_name} Shapefiles\")\n",
    "    nu.reproject_shps(dump_dir_tree[\"prepped_shapefiles\"], dump_dir_tree[\"prepped_shapefiles\"], epsg=3005)\n",
    "\n",
    "    # Render PDFs\n",
    "    if search_images:\n",
    "        LOGGER.info(f\"Rendering {project_name} PDFs\")\n",
    "        pdf_path_list = su.get_dir_item_paths(dump_dir_tree[\"pdfs\"])\n",
    "        i = 1\n",
    "        for path in pdf_path_list:\n",
    "            su.render_pdf_pages(path, out_dir=dump_dir_tree[\"pdf_images\"])\n",
    "            LOGGER.debug(f\"Rendering: {i}/{len(pdf_path_list)} for {project_name}\")\n",
    "            i += 1\n",
    "\n",
    "        LOGGER.info(f'Semantically searching {project_name} images...')\n",
    "        image_corpus_paths = su.get_dir_item_paths(dump_dir_tree[\"images\"])\n",
    "        image_corpus_paths.extend(su.get_dir_item_paths(dump_dir_tree[\"pdf_images\"]))\n",
    "                                                                \n",
    "        image_hits = su.semantic_search_images(image_corpus_paths,\n",
    "                                            query=\"A map of a proposed project\",\n",
    "                                            model=IMG_MODEL, top_k=top_k_images,\n",
    "                                            batch_size=1000,\n",
    "                                            )\n",
    "        \n",
    "        # Get paths for copying data\n",
    "        image_hit_paths = [i[\"file_path\"] for i in image_hits]\n",
    "        su.gather_files(image_hit_paths, dump_dir_tree[\"image_hits\"]) # Copy search results locally\n",
    "\n",
    "    prepped_shapefile_paths = su.get_dir_item_paths(dump_dir_tree[\"prepped_shapefiles\"])\n",
    "\n",
    "    # Create staging area\n",
    "    staging_area_dict = su.make_staging_dir(dest_dir, project_name, ';'.join(drive_locations))\n",
    "\n",
    "    # Copy data to staging area\n",
    "    LOGGER.info(f'Copying {project_name} data to network drive...')\n",
    "    if search_images:\n",
    "        su.gather_files(image_hit_paths, staging_area_dict[\"image_folder\"])\n",
    "\n",
    "    su.gather_files(prepped_shapefile_paths, staging_area_dict[\"shapefile_folder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c67dc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name_200': (200,\n",
       "  ['path/to/drive_location1', 'path/to/drive_location2', Ellipsis])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a data structure to iterate through for batch processing projects\n",
    "\n",
    "projects = {\n",
    "            'project_name_200':\\\n",
    "                (200, ['path/to/drive_location1', 'path/to/drive_location2', ...]),\n",
    "            }\n",
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for prj_name, prj_info in tqdm(projects.items(), desc='Processing '):\n",
    "    try:\n",
    "        prep_project(project_name=prj_name, uid=prj_info[0], drive_locations=prj_info[1],\n",
    "                    dest_dir=r'path/to/staging/area',\n",
    "                    search_images=False,\n",
    "                    )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to prep project {prj_name}: {e}\")\n",
    "        LOGGER.critical(f\"Failed to prep project {prj_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
